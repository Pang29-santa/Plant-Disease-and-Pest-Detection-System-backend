"""
TensorFlow Model Service
Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• TensorFlow ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä‡πÅ‡∏•‡∏∞‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Image Preprocessing ‡πÅ‡∏•‡∏∞ Test Time Augmentation (TTA) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Domain Gap
"""

import os
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    logging.getLogger(__name__).warning("OpenCV not available. Smart cropping disabled. Run: pip install opencv-python")

try:
    from rembg import remove
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False
    logging.getLogger(__name__).warning("rembg not available. Background removal disabled. Run: pip install rembg")

logger = logging.getLogger(__name__)

# ============================================
# Model Configuration
# ============================================
MODEL_PATH = Path("D:/pang/project/backend_fastapi/fine_tuned_v2/fine_tuned_v2_final.keras")
IMG_SIZE = 160  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

# ============================================
# Class Mapping (16 Classes)
# ‡πÅ‡∏°‡∏õ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Fine-tuned ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏£‡∏Ñ/‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
# ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å fine_tuned_v2 (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 98.1%)
# ============================================
CLASS_MAPPING = {
    "Anthracnose": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡πÅ‡∏≠‡∏ô‡πÅ‡∏ó‡∏£‡∏Ñ‡πÇ‡∏ô‡∏™",
        "name_en": "Anthracnose",
        "category": "disease",
        "type": "1",
    },
    "Bemisia tabaci": {
        "name_th": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß",
        "name_en": "Bemisia tabaci",
        "category": "pest",
        "type": "2",
    },
    "Cercospora Leaf Spot": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡πÅ‡∏ú‡∏•‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÑ‡∏´‡∏°‡πâ",
        "name_en": "Cercospora Leaf Spot",
        "category": "disease",
        "type": "1",
    },
    "Common Cutworm": {
        "name_th": "‡∏´‡∏ô‡∏≠‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ‡∏ú‡∏±‡∏Å",
        "name_en": "Common Cutworm",
        "category": "pest",
        "type": "2",
    },
    "Diamondback Moth": {
        "name_th": "‡∏´‡∏ô‡∏≠‡∏ô‡πÉ‡∏¢‡∏ú‡∏±‡∏Å",
        "name_en": "Diamondback Moth",
        "category": "pest",
        "type": "2",
    },
    "Downy Mildew": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡∏ô‡πâ‡∏≥‡∏Ñ‡πâ‡∏≤‡∏á",
        "name_en": "Downy Mildew",
        "category": "disease",
        "type": "1",
    },
    "Flea Beetle": {
        "name_th": "‡∏î‡πâ‡∏ß‡∏á‡∏´‡∏°‡∏±‡∏î‡∏ú‡∏±‡∏Å",
        "name_en": "Flea Beetle",
        "category": "pest",
        "type": "2",
    },
    "Leaf Blight": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ",
        "name_en": "Leaf Blight",
        "category": "disease",
        "type": "1",
    },
    "Leaf Miner": {
        "name_th": "‡∏´‡∏ô‡∏≠‡∏ô‡∏ä‡∏≠‡∏ô‡πÉ‡∏ö",
        "name_en": "Leaf Miner",
        "category": "pest",
        "type": "2",
    },
    "Leaf Spot Disease": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏à‡∏∏‡∏î",
        "name_en": "Leaf Spot Disease",
        "category": "disease",
        "type": "1",
    },
    "Leafhopper": {
        "name_th": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô",
        "name_en": "Leafhopper",
        "category": "pest",
        "type": "2",
    },
    "Powdery Mildew": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡πÅ‡∏õ‡πâ‡∏á",
        "name_en": "Powdery Mildew",
        "category": "disease",
        "type": "1",
    },
    "Red Pumpkin Beetle": {
        "name_th": "‡∏î‡πâ‡∏ß‡∏á‡πÄ‡∏ï‡πà‡∏≤‡πÅ‡∏ï‡∏á‡πÅ‡∏î‡∏á",
        "name_en": "Red Pumpkin Beetle",
        "category": "pest",
        "type": "2",
    },
    "Rust Disease": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡∏™‡∏ô‡∏¥‡∏°",
        "name_en": "Rust Disease",
        "category": "disease",
        "type": "1",
    },
    "Thrips": {
        "name_th": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü",
        "name_en": "Thrips",
        "category": "pest",
        "type": "2",
    },
    "White Rust Disease": {
        "name_th": "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡∏™‡∏ô‡∏¥‡∏°‡∏Ç‡∏≤‡∏ß",
        "name_en": "White Rust Disease",
        "category": "disease",
        "type": "1",
    },
}


class ResultValidator:
    """
    Validator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä‡∏Å‡∏±‡∏ö‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
    """
    
    # ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏Å‡∏±‡∏ô (Confusable Classes)
    # ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÅ‡∏°‡∏•‡∏á‡∏Å‡∏±‡∏î
    DISEASE_LOOKING_LIKE_PEST = {
        "Leaf_Spot_Disease",  # ‡πÉ‡∏ö‡∏à‡∏∏‡∏î ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏£‡∏≠‡∏¢‡∏Å‡∏±‡∏î
        "Leaf_Blight",        # ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏£‡∏≠‡∏¢‡πÑ‡∏´‡∏°‡πâ‡∏à‡∏≤‡∏Å‡πÅ‡∏°‡∏•‡∏á
        "Cercospora_Leaf",    # ‡πÉ‡∏ö‡∏à‡∏∏‡∏î‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÇ‡∏Ñ‡∏™pora
    }
    
    # ‡πÅ‡∏°‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÇ‡∏£‡∏Ñ
    PEST_LOOKING_LIKE_DISEASE = {
        "Leaf_Miner",         # ‡∏´‡∏ô‡∏≠‡∏ô‡∏ä‡∏≠‡∏ô‡πÉ‡∏ö ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡πÇ‡∏£‡∏Ñ
        "flea_beetle",        # ‡∏î‡πâ‡∏ß‡∏á‡∏´‡∏°‡∏±‡∏î‡∏ú‡∏±‡∏Å ‡∏£‡∏π‡∏Å‡∏±‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏à‡∏∏‡∏î‡πÇ‡∏£‡∏Ñ
    }
    
    @classmethod
    def validate_prediction_consistency(cls, results: List[Dict], pred_probs: np.ndarray, class_names: List[str]) -> Dict:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á top predictions
        
        Args:
            results: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå top 3
            pred_probs: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™
            class_names: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            
        Returns:
            Dictionary ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
        """
        if len(results) < 2:
            return {"is_consistent": True, "warnings": []}
        
        warnings = []
        primary = results[0]
        secondary = results[1]
        
        primary_category = primary.get("category", "unknown")
        secondary_category = secondary.get("category", "unknown")
        primary_conf = primary.get("confidence", 0)
        secondary_conf = secondary.get("confidence", 0)
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Top 2 ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏±‡∏ô (‡πÇ‡∏£‡∏Ñ vs ‡πÅ‡∏°‡∏•‡∏á) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        category_conflict = (primary_category != secondary_category and 
                            primary_category in ["disease", "pest"] and
                            secondary_category in ["disease", "pest"])
        
        if category_conflict:
            confidence_gap = abs(primary_conf - secondary_conf)
            
            if confidence_gap < 0.15:  # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 15%
                warnings.append({
                    "type": "category_conflict",
                    "level": "high",
                    "message": f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á{cls._get_category_name(primary_category)}‡∏Å‡∏±‡∏ö{cls._get_category_name(secondary_category)}",
                    "suggestion": "‡∏Ñ‡∏ß‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏≤‡πÄ‡∏õ‡∏•‡πà‡∏≤",
                    "confidence_gap": round(float(confidence_gap), 3),
                })
            elif confidence_gap < 0.30:  # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á 15-30%
                warnings.append({
                    "type": "category_conflict",
                    "level": "medium",
                    "message": f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á{cls._get_category_name(primary_category)}‡∏Å‡∏±‡∏ö{cls._get_category_name(secondary_category)}",
                    "suggestion": "‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏î‡∏π‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°",
                    "confidence_gap": round(float(confidence_gap), 3),
                })
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ primary prediction ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        primary_class = primary.get("class_name", "")
        if primary_class in cls.DISEASE_LOOKING_LIKE_PEST and primary_category == "disease":
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡πÉ‡∏ô top 3 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            has_pest_in_top3 = any(r.get("category") == "pest" for r in results)
            if has_pest_in_top3:
                warnings.append({
                    "type": "look_alike",
                    "level": "medium",
                    "message": "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÅ‡∏°‡∏•‡∏á‡∏Å‡∏±‡∏î ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≠‡∏¢‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà",
                    "suggestion": "‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏Å‡∏±‡∏î ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ",
                })
        
        elif primary_class in cls.PEST_LOOKING_LIKE_DISEASE and primary_category == "pest":
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ô top 3 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            has_disease_in_top3 = any(r.get("category") == "disease" for r in results)
            if has_disease_in_top3:
                warnings.append({
                    "type": "look_alike",
                    "level": "medium",
                    "message": "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà",
                    "suggestion": "‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä",
                })
        
        # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì category confidence (‡∏£‡∏ß‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÇ‡∏£‡∏Ñ‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô)
        disease_confidence = sum(
            float(pred_probs[i]) for i, name in enumerate(class_names)
            if CLASS_MAPPING.get(name, {}).get("category") == "disease"
        )
        pest_confidence = sum(
            float(pred_probs[i]) for i, name in enumerate(class_names)
            if CLASS_MAPPING.get(name, {}).get("category") == "pest"
        )
        
        category_analysis = {
            "disease_total_confidence": round(float(disease_confidence), 4),
            "pest_total_confidence": round(float(pest_confidence), 4),
            "predicted_category": primary_category,
            "category_confidence_ratio": round(float(max(disease_confidence, pest_confidence) / (disease_confidence + pest_confidence + 1e-7)), 4),
        }
        
        return {
            "is_consistent": len(warnings) == 0,
            "warnings": warnings,
            "category_analysis": category_analysis,
            "has_category_conflict": category_conflict,
        }
    
    @staticmethod
    def _get_category_name(category: str) -> str:
        """‡πÅ‡∏õ‡∏•‡∏á category code ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        return "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä" if category == "disease" else "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä" if category == "pest" else category


class ImagePreprocessor:
    """
    Preprocessor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö dataset ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô
    ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Domain Gap ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÄ‡∏ó‡∏£‡∏ô
    """
    
    @staticmethod
    def center_crop(img: Image.Image, crop_ratio: float = 0.9) -> Image.Image:
        """Crop ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏´‡∏•‡∏±‡∏Å"""
        width, height = img.size
        new_width = int(width * crop_ratio)
        new_height = int(height * crop_ratio)
        left = (width - new_width) // 2
        top = (height - new_height) // 2
        right = left + new_width
        bottom = top + new_height
        return img.crop((left, top, right, bottom))
    
    @staticmethod
    def auto_contrast(img: Image.Image, cutoff: int = 0) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö contrast ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏î‡∏∏‡∏•"""
        return ImageOps.autocontrast(img, cutoff=cutoff)
    
    @staticmethod
    def equalize_histogram(img: Image.Image) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö histogram ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏î‡∏∏‡∏•"""
        return ImageOps.equalize(img)
    
    @staticmethod
    def adjust_brightness(img: Image.Image, factor: float = 1.0) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á"""
        enhancer = ImageEnhance.Brightness(img)
        return enhancer.enhance(factor)
    
    @staticmethod
    def adjust_contrast(img: Image.Image, factor: float = 1.0) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î"""
        enhancer = ImageEnhance.Contrast(img)
        return enhancer.enhance(factor)
    
    @staticmethod
    def adjust_sharpness(img: Image.Image, factor: float = 1.0) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö"""
        enhancer = ImageEnhance.Sharpness(img)
        return enhancer.enhance(factor)
    
    @staticmethod
    def denoise(img: Image.Image) -> Image.Image:
        """‡∏•‡∏î noise ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        return img.filter(ImageFilter.MedianFilter(size=3))
    
    @staticmethod
    def remove_color_cast(img: Image.Image) -> Image.Image:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á (white balance)"""
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array
        img_array = np.array(img).astype(np.float32)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏™‡∏µ
        r_mean = np.mean(img_array[:, :, 0])
        g_mean = np.mean(img_array[:, :, 1])
        b_mean = np.mean(img_array[:, :, 2])
        
        # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏ß‡∏°
        avg = (r_mean + g_mean + b_mean) / 3.0
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏µ
        img_array[:, :, 0] = np.clip(img_array[:, :, 0] * (avg / r_mean), 0, 255)
        img_array[:, :, 1] = np.clip(img_array[:, :, 1] * (avg / g_mean), 0, 255)
        img_array[:, :, 2] = np.clip(img_array[:, :, 2] * (avg / b_mean), 0, 255)
        
        return Image.fromarray(img_array.astype(np.uint8))
    
    @staticmethod
    def remove_background_if_available(img: Image.Image) -> Image.Image:
        """‡∏•‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏¥‡πâ‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏´‡∏•‡∏±‡∏Å (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á rembg)"""
        if not REMBG_AVAILABLE:
            return img
        try:
            logger.info("Applying background removal...")
            # rembg ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö PIL
            result = remove(img)
            # rembg ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô RGBA (‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™) ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ã‡πâ‡∏≠‡∏ô‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß
            background = Image.new("RGB", result.size, (255, 255, 255))
            background.paste(result, mask=result.split()[3]) 
            return background
        except Exception as e:
            logger.error(f"Background removal failed: {e}")
            return img

    @staticmethod
    def smart_crop_if_available(img: Image.Image) -> Image.Image:
        """‡∏Ñ‡∏£‡∏≠‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß/‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á opencv-python)"""
        if not OPENCV_AVAILABLE:
            return img
        try:
            logger.info("Applying smart crop...")
            # ‡πÅ‡∏õ‡∏•‡∏á PIL ‡πÄ‡∏õ‡πá‡∏ô OpenCV format (BGR)
            open_cv_image = np.array(img.convert('RGB'))
            open_cv_image = open_cv_image[:, :, ::-1].copy() # RGB to BGR

            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô HSV
            hsv = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2HSV)

            # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
            lower_green = np.array([25, 40, 40])
            upper_green = np.array([90, 255, 255])
            mask_green = cv2.inRange(hsv, lower_green, upper_green)

            # ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•/‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á/‡πÅ‡∏î‡∏á (‡πÇ‡∏£‡∏Ñ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πÅ‡∏õ‡∏•‡∏Å‡πÜ ‡∏ó‡πà‡∏≤‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÉ‡∏ö‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß)
            lower_brown = np.array([0, 40, 40])
            upper_brown = np.array([25, 255, 255])
            mask_brown = cv2.inRange(hsv, lower_brown, upper_brown)

            full_mask = cv2.bitwise_or(mask_green, mask_brown)

            # ‡∏´‡∏≤ Contours
            contours, _ = cv2.findContours(full_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return img
                
            x_min, y_min = img.width, img.height
            x_max, y_max = 0, 0
            
            for c in contours:
                if cv2.contourArea(c) < 500: # ‡∏Å‡∏£‡∏≠‡∏á noise
                    continue
                x, y, w, h = cv2.boundingRect(c)
                x_min = min(x_min, x)
                y_min = min(y_min, y)
                x_max = max(x_max, x + w)
                y_max = max(y_max, y + h)
                
            if x_min >= x_max or y_min >= y_max:
                return img
                
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
            pad_w = int((x_max - x_min) * 0.1)
            pad_h = int((y_max - y_min) * 0.1)
            
            x_min = max(0, x_min - pad_w)
            y_min = max(0, y_min - pad_h)
            x_max = min(img.width, x_max + pad_w)
            y_max = min(img.height, y_max + pad_h)
            
            return img.crop((x_min, y_min, x_max, y_max))

        except Exception as e:
            logger.error(f"Smart cropping failed: {e}")
            return img

    @classmethod
    def preprocess_for_model(
        cls, 
        image_path: str, 
        enhance: bool = True,
        remove_bg_tint: bool = True,
        remove_bg: bool = True,
        smart_crop: bool = True
    ) -> Image.Image:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
        
        Args:
            image_path: Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            enhance: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            remove_bg_tint: ‡∏õ‡∏£‡∏±‡∏ö white balance ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            remove_bg: ‡∏•‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏û‡∏∑‡∏ä‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            smart_crop: ‡∏Ñ‡∏£‡∏≠‡∏õ‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            
        Returns:
            PIL Image ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
        """
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        img = Image.open(image_path).convert('RGB')
        
        # [‡πÉ‡∏´‡∏°‡πà] 1. Smart Crop - ‡∏Ñ‡∏£‡∏≠‡∏õ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ö‡πÑ‡∏°‡πâ/‡∏£‡∏≠‡∏¢‡πÇ‡∏£‡∏Ñ
        if smart_crop:
            img = cls.smart_crop_if_available(img)
            
        # [‡πÉ‡∏´‡∏°‡πà] 2. ‡∏•‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏û‡∏∑‡∏ä
        if remove_bg:
            img = cls.remove_background_if_available(img)
        
        if not enhance:
            return img
        
        # 1. ‡∏õ‡∏£‡∏±‡∏ö white balance
        if remove_bg_tint:
            img = cls.remove_color_cast(img)
        
        # 2. ‡∏õ‡∏£‡∏±‡∏ö auto contrast
        img = cls.auto_contrast(img, cutoff=1)
        
        # 3. ‡∏õ‡∏£‡∏±‡∏ö brightness ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
        img = cls.adjust_brightness(img, factor=1.1)
        
        # 4. ‡∏õ‡∏£‡∏±‡∏ö contrast
        img = cls.adjust_contrast(img, factor=1.1)
        
        # 5. ‡∏•‡∏î noise
        img = cls.denoise(img)
        
        # 6. ‡∏õ‡∏£‡∏±‡∏ö sharpness
        img = cls.adjust_sharpness(img, factor=1.2)
        
        return img


class TensorFlowModelService:
    """
    Singleton Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• TensorFlow
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Test Time Augmentation (TTA) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    """
    _instance = None
    _model = None
    _class_names = None
    _is_loaded = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._is_loaded:
            self.load_model()

    def load_model(self) -> bool:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• TensorFlow ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .keras
        
        Returns:
            bool: True ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        """
        try:
            import tensorflow as tf
            
            if not MODEL_PATH.exists():
                logger.error(f"‚ùå Model file not found: {MODEL_PATH}")
                return False

            logger.info(f"üîÑ Loading TensorFlow model from: {MODEL_PATH}")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
            self._model = tf.keras.models.load_model(str(MODEL_PATH))
            
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å mapping
            self._class_names = list(CLASS_MAPPING.keys())
            
            self._is_loaded = True
            logger.info(f"‚úÖ TensorFlow model loaded successfully!")
            logger.info(f"   - Input shape: {self._model.input_shape}")
            logger.info(f"   - Output classes: {len(self._class_names)}")
            logger.info(f"   - Classes: {', '.join(self._class_names)}")
            
            return True
            
        except ImportError:
            logger.error("‚ùå TensorFlow not installed. Run: pip install tensorflow")
            return False
        except Exception as e:
            logger.error(f"‚ùå Error loading model: {e}")
            return False

    def is_ready(self) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        return self._is_loaded and self._model is not None

    def preprocess_image(self, image_path: str, enhance: bool = True) -> Optional[np.ndarray]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
        
        Args:
            image_path: Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            enhance: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            
        Returns:
            numpy array ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ error
        """
        try:
            # ‡πÉ‡∏ä‡πâ ImagePreprocessor
            img = ImagePreprocessor.preprocess_for_model(image_path, enhance=enhance)
            
            # Resize ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            img_resized = img.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array ‡πÅ‡∏•‡∏∞ normalize (0-1)
            img_array = np.array(img_resized) / 255.0
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° batch dimension (1, 160, 160, 3)
            img_array = np.expand_dims(img_array, axis=0)
            
            return img_array
            
        except Exception as e:
            logger.error(f"‚ùå Error preprocessing image: {e}")
            return None
    
    def predict_with_tta(
        self, 
        image_path: str, 
        n_augmentations: int = 5,
        enhance: bool = True
    ) -> Optional[Dict]:
        """
        ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Test Time Augmentation (TTA)
        ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ augment ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        
        Args:
            image_path: Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            n_augmentations: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ augment (default: 5)
            enhance: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            
        Returns:
            Dictionary ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        """
        if not self.is_ready():
            logger.error("‚ùå Model not loaded")
            return None
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏Å
            img = ImagePreprocessor.preprocess_for_model(image_path, enhance=enhance)
            img_resized = img.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)
            
            all_predictions = []
            
            # 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            img_array = np.array(img_resized) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            pred = self._model.predict(img_array, verbose=0)
            all_predictions.append(pred[0])
            
            # 2. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ flip ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
            img_flipped_h = img_resized.transpose(Image.FLIP_LEFT_RIGHT)
            img_array = np.array(img_flipped_h) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            pred = self._model.predict(img_array, verbose=0)
            all_predictions.append(pred[0])
            
            # 3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ flip ‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
            img_flipped_v = img_resized.transpose(Image.FLIP_TOP_BOTTOM)
            img_array = np.array(img_flipped_v) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            pred = self._model.predict(img_array, verbose=0)
            all_predictions.append(pred[0])
            
            # 4. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (¬±5 ‡∏≠‡∏á‡∏®‡∏≤)
            img_rotated_p5 = img_resized.rotate(5, fillcolor=(128, 128, 128))
            img_array = np.array(img_rotated_p5) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            pred = self._model.predict(img_array, verbose=0)
            all_predictions.append(pred[0])
            
            img_rotated_m5 = img_resized.rotate(-5, fillcolor=(128, 128, 128))
            img_array = np.array(img_rotated_m5) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            pred = self._model.predict(img_array, verbose=0)
            all_predictions.append(pred[0])
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            avg_predictions = np.mean(all_predictions, axis=0)
            
            logger.info(f"üîç TTA completed with {len(all_predictions)} augmentations")
            
            return avg_predictions
            
        except Exception as e:
            logger.error(f"‚ùå Error during TTA: {e}")
            return None

    def predict(
        self, 
        image_path: str, 
        use_tta: bool = True,
        enhance: bool = True,
        confidence_threshold: float = 0.5
    ) -> Optional[Dict]:
        """
        ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• TensorFlow
        
        Args:
            image_path: Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            use_tta: ‡πÉ‡∏ä‡πâ Test Time Augmentation ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            enhance: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            confidence_threshold: ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            
        Returns:
            Dictionary ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ error
        """
        if not self.is_ready():
            logger.error("‚ùå Model not loaded")
            return None

        try:
            logger.info(f"üîç Predicting image: {image_path}")
            logger.info(f"   - Use TTA: {use_tta}")
            logger.info(f"   - Enhance: {enhance}")
            
            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ TTA
            if use_tta:
                pred_probs = self.predict_with_tta(image_path, enhance=enhance)
                if pred_probs is None:
                    # Fallback ‡∏ñ‡πâ‡∏≤ TTA ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
                    img_array = self.preprocess_image(image_path, enhance=enhance)
                    if img_array is None:
                        return None
                    predictions = self._model.predict(img_array, verbose=0)
                    pred_probs = predictions[0]
            else:
                img_array = self.preprocess_image(image_path, enhance=enhance)
                if img_array is None:
                    return None
                predictions = self._model.predict(img_array, verbose=0)
                pred_probs = predictions[0]
            
            # ‡∏´‡∏≤ top 3 predictions
            top_3_indices = np.argsort(pred_probs)[-3:][::-1]
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results = []
            for idx in top_3_indices:
                class_name = self._class_names[idx]
                class_info = CLASS_MAPPING.get(class_name, {})
                
                results.append({
                    "class_name": class_name,
                    "name_th": class_info.get("name_th", class_name),
                    "name_en": class_info.get("name_en", class_name),
                    "confidence": float(pred_probs[idx]),
                    "confidence_percent": round(float(pred_probs[idx]) * 100, 2),
                    "category": class_info.get("category", "unknown"),
                    "type": class_info.get("type", "0"),
                })

            # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å (‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1)
            primary_result = results[0]
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏ö‡πÇ‡∏£‡∏Ñ/‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î)
            is_detected = bool(primary_result["confidence"] > confidence_threshold)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì uncertainty (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô) ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á top 2
            uncertainty = float(pred_probs[top_3_indices[0]] - pred_probs[top_3_indices[1]])
            is_uncertain = bool(uncertainty < 0.2)  # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 20% = ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÇ‡∏£‡∏Ñ vs ‡πÅ‡∏°‡∏•‡∏á)
            validation_result = ResultValidator.validate_prediction_consistency(
                results, pred_probs, self._class_names
            )
            
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ category conflict ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö is_uncertain
            if validation_result.get("has_category_conflict", False) and uncertainty < 0.25:
                is_uncertain = True
            
            # ‡∏õ‡∏£‡∏±‡∏ö confidence ‡∏ï‡∏≤‡∏° category analysis
            category_analysis = validation_result.get("category_analysis", {})
            category_conf_ratio = category_analysis.get("category_confidence_ratio", 1.0)
            
            # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 60% ‡πÉ‡∏´‡πâ‡∏•‡∏î confidence ‡∏•‡∏á
            adjusted_confidence = primary_result["confidence"]
            if category_conf_ratio < 0.6:
                adjusted_confidence *= 0.8  # ‡∏•‡∏î confidence 20%
                is_uncertain = True
            
            return {
                "success": True,
                "model": "TensorFlow_MobileNetV2",
                "is_detected": bool(is_detected),
                "is_uncertain": bool(is_uncertain),
                "uncertainty_score": round(float(uncertainty), 4),
                "is_plant": True,
                "primary": {
                    **primary_result,
                    "adjusted_confidence": round(float(adjusted_confidence), 4),
                    "adjusted_confidence_percent": round(float(adjusted_confidence) * 100, 2),
                },
                "top_3": results,
                "all_predictions": [
                    {
                        "class_name": str(self._class_names[i]),
                        "confidence": float(pred_probs[i]),
                        "confidence_percent": round(float(pred_probs[i]) * 100, 2),
                    }
                    for i in range(len(self._class_names))
                ],
                "preprocessing": {
                    "enhanced": bool(enhance),
                    "tta_used": bool(use_tta),
                },
                "validation": validation_result,  # ‚≠ê ‡πÉ‡∏´‡∏°‡πà: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error during prediction: {e}")
            return {
                "success": False,
                "error": str(e),
            }

    def get_model_info(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        return {
            "loaded": self.is_ready(),
            "model_path": str(MODEL_PATH),
            "model_type": "MobileNetV2 (Fine-tuned v2)",
            "accuracy": "98.1%",
            "input_size": IMG_SIZE,
            "num_classes": len(CLASS_MAPPING) if self._class_names else 0,
            "classes": self._class_names,
            "class_mapping": {
                cls: info["name_th"] 
                for cls, info in CLASS_MAPPING.items()
            },
            "features": {
                "tta_supported": True,
                "enhancement_supported": True,
                "uncertainty_estimation": True,
                "smart_crop": OPENCV_AVAILABLE,
                "background_removal": REMBG_AVAILABLE,
            }
        }


# ============================================
# Global Instance
# ============================================
_tf_model_service = None


def get_tf_model_service() -> TensorFlowModelService:
    """Get singleton instance of TensorFlowModelService"""
    global _tf_model_service
    if _tf_model_service is None:
        _tf_model_service = TensorFlowModelService()
    return _tf_model_service


def analyze_with_tensorflow(
    image_path: str,
    use_tta: bool = True,
    enhance: bool = True,
    confidence_threshold: float = 0.5
) -> Dict:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô wrapper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ TensorFlow
    
    Args:
        image_path: Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        use_tta: ‡πÉ‡∏ä‡πâ Test Time Augmentation ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        enhance: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        confidence_threshold: ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
        
    Returns:
        Dictionary ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    service = get_tf_model_service()
    
    if not service.is_ready():
        return {
            "success": False,
            "error": "TensorFlow model not loaded. Please check if model file exists.",
        }
    
    result = service.predict(
        image_path, 
        use_tta=use_tta,
        enhance=enhance,
        confidence_threshold=confidence_threshold
    )
    
    if result is None:
        return {
            "success": False,
            "error": "Prediction failed",
        }
    
    return result
